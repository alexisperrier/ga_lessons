---
layout: slide
title: Lesson 03 - Statistics Fundamentals
description: none
transition: slide
permalink: /03-statistics-fundamentals.html
theme: ga
---

<section  data-background-color="#000">
    <h1 class = 'white' style ="border-top: thin solid #DDD;border-bottom: thin solid #DDD;">
        <img src="assets/ga_logo_black.png" style="float:left;top:0px;">
        General Assembly
    </h1>
    <p class = 'big_title'>Statistics Fundamentals</p>
</section>
<section data-markdown>
# Statistics Fundamentals

## LEARNING OBJECTIVES

* Use NumPy and Pandas libraries to analyze datasets using basic summary statistics: mean, median, quartile, standard deviation, and correlation
* Create data visualizations : box plots and histograms- to discern characteristics and trends in a dataset
* Intro to Normal Distributions
* **Key Concept: BIAS VS. VARIANCE**
* Dealing with categorical variables

</section>

<!-- Prework and review -->
<section  data-background-color="#DA0A13">
    <h1>Lesson 3</h1>
    <p class = 'big_title'>Pre Work & Review</p>
</section>


<section data-markdown>
# Statistics Fundamentals
## Pre work
Before this lesson, you should already be able to:

* Work in Jupyter notebooks with Numpy and Pandas

</section>

<section data-markdown>
# Last Lesson Review

* Frame Good Questions with S.M.A.R.T
* Study types: Cross sectional vs longitudinal
* Numpy and Pandas

### Any questions from last class?
Note:
Exit tickets
</section>

<!-- Today -->
<section  data-background-color="#22c8c6">
    <h1>Today</h1>
    <p class = 'big_title'>Statistics Fundamentals</p>
</section>

<section data-markdown>
# Today
* Data Exploration with stats and graphs
* Normal distribution
* Bias vs Variance: Overfitting vs Underfitting
* Demo / Lab
</section>

<section data-markdown>
# Course plan
* [0  - 1h] Statistics: Mean, Median, STD, Correlation, Quartiles
* [1h  - 1h15] Bias - Variance
* [1h15  - 1h45] Normal Distribution
* [1h45  - 2h00] Data Types
* [2h  - end] Dummy Encoding

</section>


<!-- Intro -->
<section  data-background-color="#22c8c6">
    <h1>Intro</h1>
    <p class = 'big_title'>Statistics Fundamentals</p>
</section>

<section data-markdown>
# Mean / Average

* Sum of all values divided by number of values

$$a = [2,4,6,8]$$

$$\bar{a} = \frac{(2 + 4 + 6 + 8)}{4} = 10 $$

$$\bar{X} = \frac{1}{N} \sum X_{i} $$

* Sensitive to outliers
* Other means: Harmonic mean, geometric mean
* In probability Expectation of X: $$\mathbb{E}\[X\]$$
</section>

<section data-markdown>
# Median

The median refers to the midpoint in a series of numbers.

To find the median:

Arrange the numbers in order smallest to largest.

* If there is an odd number of values, the middle value is the median.

* If there is an even number of values, the  average of the middle two values is the  median.

</section>


<section data-markdown>
# Median examples

* $$a = [1,2,3,4,5] => median(a) = 3$$

* $$a = [1,2,3,4,5,6] => median(a) = \frac{3+4}{2} $$

* $$a = [10,12,18,28, 32,34, 36, 40, 1000, 10000]$$ $$ median(a) = 33$$ but $$\bar{a} = 1121$$

More robust to outliers than mean
</section>

<section data-markdown>
# Standard Deviation

**Standard deviation** \\( \sigma \\)
 measures the amount of variation of a set of data values around its mean.

![Std 01](assets/03/standard-deviation-01.png)
![Std 02](assets/03/standard-deviation-02.png)

</section>

<section data-markdown>
# Standard Deviation

Both datasets have a mean of 100 but different SDs.![Std 03](assets/03/Comparison_standard_deviations.svg)
</section>

<section data-markdown>
# SD and Mean estimator

Given a sample set

How good is the mean and SD estimators?

</section>

<section data-markdown>
# Panda / Numpy

    a = [1,2,3,4,5,6,7,8,9,0]

    np.mean(a)

    np.std(a)

    np.describe(a)

</section>

<section data-markdown>
# Correlation

Correlation is a measure of the dependence between 2 variables X and Y.

* X increases => Y increases
    * positive correlation, think children's age => height
* X increases => Y decreases
    * negative correlation, think adult's age => eyesight

### Independent variables

X increases no observable change in the behavior of Y

(Parent => teenager for instance)

</section>

<section data-markdown>
# Correlation

Many different ways to calculate correlation.

Most common one is [Pearson Correlation](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient)

$$ X = \{x_1, .... x_N\} \qquad Y = \{ y_1, ... , y_N\}  $$

Correlation between X and Y:

$$ \rho_{X,Y} =  \frac{ \sum (x_i - \bar{x})(y_i - \bar{y})  }{ \sqrt{\sum (x_i - \bar{x})^2 } \sqrt{\sum (y_i - \bar{y})^2 }    }  $$
where

$$\bar{x} = \frac{1}{N} \sum x_i \qquad and \qquad \bar{y} = \frac{1}{N} \sum y_i $$

</section>

<section data-markdown>
# Correlation

![Pearson Correlation Coefficient](assets/03/pearson-correlation-coefficient-illustration.png)

</section>


<section data-markdown>
# QUARTILES AND INTERQUARTILE RANGE

Quartiles divide a rank-ordered data set into four equal parts.

The values that divide each part are called first, second, and third quartiles, denoted Q1, Q2, and Q3, respectively.

The interquartile range (IQR) is Q3 - Q1, a measure of variability.

![IQR](assets/03/iqr.png)


</section>

<section data-markdown>
# BOXPLOT

![boxplot](assets/03/simple_box_defs.gif)

<!-- <div style="float: right"> -->
![boxplot](assets/03/complex_box_defs.gif)
<!-- </div> -->
</section>

<section data-markdown>
# Knowledge Check

Plot the boxplot for the Boston Housing dataset for ....

</section>


<!-- Bias Variance -->
<section  data-background-color="#22c8c6">
    <h1>Bias - Variance</h1>
    <p class = 'big_title'>Bias - Variance</p>
    <p>The bias–variance tradeoff is a central problem in supervised learning.</p>
</section>

<section data-markdown>
# Bias - Variance
### General problem

* Prediction Task: regression, classification
* Dataset: split between train and test (unseen data)
* Model: trained on the train data

You want that model to
1. get good predictions on the train data, be well trained
2. generalize to the unseen data with good performance.


Ideally, one wants to choose a model that both accurately captures the regularities in its training data, but also generalizes well to unseen data.

For that you need the model to minize to distinct types of error: Bias and Variance
</section>

<section data-markdown>
# Bias - Variance

### Bias
* Error due to bias is calculated at the difference between the expected prediction of our model and the correct value we are trying to predict.

* Imagine creating multiple models on various datasets.
Bias measures how far off in general models’ predictions are from the correct value.

</section>

<section data-markdown>
# Bias - Variance

### Variance
* Error due to variance is taken as the variability of a model prediction for a given point.

* Imagine creating multiple models on various datasets.
The variance is how much the predictions for a given point vary between different realizations of the model.

</section>

<section data-markdown>
# Bias Variance

Over fitting: performs highly on training dataset but poorly on new data \\( \Leftrightarrow \\) High variance

Underfitting: Your model performs poorly on training and unseen data \\( \Leftrightarrow \\) High Bias
</section>


<section data-markdown>
# Knowledge Check
</section>

<!-- Normal Distribution -->
<section  data-background-color="#22c8c6">
    <h1>Stats</h1>
    <p class = 'white big_title'>Normal Distribution</p>
</section>

<section data-markdown>
# Normal Distribution
Codealong:
https://github.com/alexperrier/ds-curriculum/blob/master/lessons/lesson-03/code/lesson-3-demo.ipynb

Launch a jupyter notebook
</section>

<section data-markdown>
# Normal Distribution
A normal distribution is often a key assumption to many models.

The normal distribution depends upon the mean and the standard deviation.

The mean determines the center of the distribution.  The standard deviation determines the height and width of the distribution.

</section>


<section data-markdown>
# Law of large numbers
String assumption on the data: independent and identically distributed

A lot => distribution (inherent law) is a normal distribution

</section>

<section data-markdown>
# Normal Distribution
Interpretation

2 sigma

</section>

<section data-markdown>
# Standard Normal Distribution: N(0,1)

</section>


<section data-markdown>
# Skewness

</section>

<section data-markdown>
# Kurtosis

</section>

<section data-markdown>
# Transformation to correct Skewness

</section>

<section data-markdown>
# Knowledge Check
https://github.com/alexperrier/ds-curriculum/tree/master/lessons/lesson-03/assets/images
</section>


<section  data-background-color="#22c8c6">
    <h1>Data Types</h1>
    <p class = 'big_title'>Categorical vs Continuous</p>
</section>

<section data-markdown>
# Data Types
## Continous
Numeric variables can take on a large range of non-predetermined, quantitative values. These are things such as height, income, etc.

## Categorical
Categorical variables can take on a specific set of variables.

These are things such as gender, colors, countries, fare level, courses, music genre, housing types, ....

## Continous to Categorical

* Age [0 to 120] becomes Age Group [0-18, 18-25, 25-35, ...]
* Free text becomes categories

</section>


<section  data-background-color="#22c8c6">
    <h1>Categorical values</h1>
    <p class = 'big_title'>Dummy Variables - one hot encoding</p>
</section>

<section data-markdown>
# Categorical - what's the problem?

* Need numbers not strings
* Coded as 1,2,3 induces order among categories

</section>

<section data-markdown>
# Categorical

Convert category into N variables
ex:
In fact need N-1 not N
</section>


<section data-markdown>
# Categorical

We’ll draw out how categorical variables can be represented without implying order.

First, let’s choose a reference category.  This will be our “base” category.

It’s often good to choose the category with the largest sample size and a criteria that will help model interpretation.  If we are testing for a disease, the reference category would be people without the disease.
</section>

<section data-markdown>
# Let’s see our dummy variables.

</section>

<section data-markdown>
# Knowledge check

We can do this for a gender variable with two categories:  male and female.

How many dummy variables need to be created?
</section>


<section data-markdown>
# In pandas: pd.get_dummies()

</section>


<!-- Lesson Review 9:15 -->
<section  data-background-color="#22c8c6">
    <h1>Lesson</h1>
    <p class = 'big_title'> Lesson Review </p>
</section>

<!-- Before Next Class -->
<section  data-background-color="#DA0A13">
    <h1>Course</h1>
    <p class = 'big_title'>Before Next Class</p>
</section>


<!-- Q&A -->
<section  data-background-color="#FED500">
    <h1>Q & A</h1>
    <p class = 'big_title'>5 Questions about today</p>
</section>

<!-- Exit ticket -->
<section  data-background-color="#FC9CB4">
    <h1>Exit ticket</h1>
    <p class = 'big_title'>Exit ticket</p>
</section>

<section data-markdown>
# Links
</section>
